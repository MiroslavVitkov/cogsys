{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANLP 2017 - Assignment 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sophia Student, 1234567* (enter your name/student id number here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">Due: Tuesday, November 7</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "**NOTE**<br><br>\n",
    "\n",
    "Please first fill in your name and id number at the top of the assignment, and **rename** the assignment file to **yourlastname-anlp-1.ipynb**<br><br>\n",
    "Problems and questions are given in blue boxes like this one. All grey and white boxes must be filled by you (they either require code or a (brief!) discussion). <br><br>\n",
    "Please hand in your assignment by the deadline via Moodle upload (we will provide a link). In case of questions, you can contact Tatjana or Jens via email, or via the Moodle forum (preferred).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Use Python 3 and the Natural Language Toolkit (NLTK) for the problems. The __[NLTK book](http://www.nltk.org/book/)__ (\"Natural Language Processing with Python\")\n",
    "is available online.\n",
    "<br>\n",
    "<br>\n",
    "You should also familiarize yourselves with working with unicode and\n",
    "UTF-8 in Python. The session on Friday, October 27 can be used to get\n",
    "up to speed with Python, NLTK, and the packages used in the assignments below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Zipf's Law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Empirically verify Zipf's law. Use the following freely available corpora, which are provided via the course's Moodle page:<br>\n",
    "\n",
    "-  King James Bible, http://www.gutenberg.org/cache/epub/10/pg10.txt\n",
    "-  The Jungle Book, http://www.gutenberg.org/cache/epub/35997/pg35997.txt\n",
    "-  SETIMES Turkish-Bulgarian parallel newspaper text, http://opus.lingfil.uu.se/download.php?f=SETIMES2/bg-tr.txt.zip\n",
    "\n",
    "\n",
    "For each corpus, produce a list of unique word forms sorted by descending frequency. Preferably using the Python libraries `numpy` and `matplotlib`, plot the  frequency  curves  for  the  corpora.  Make  sure  to  provide  both  a  linear curve, and a log-log curve (see methods `matplotlib.pyplot.plot` and `matplotlib.pyplot.loglog`). \n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KJBIBLE = \"kjbible.txt\"  # do not change file names\n",
    "JBOOK = \"junglebook.txt\"\n",
    "SETIMES_TR = \"SETIMES2.bg-tr.tr\"\n",
    "SETIMES_BG = \"SETIMES2.bg-tr.bg\"\n",
    "\n",
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Provide a brief discussion of the findings.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your discussion goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Random Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "In  this  assignment,  you  will  reimplement  the  \"Dissociated  Press\"  system\n",
    "that  was  developed  by  MIT  students  in  the  1970s  (see  Wikipedia).  The\n",
    "purpose of this system is to generate random text from an\n",
    "n-gram model over a corpus.\n",
    "<br><br>\n",
    "Unfortunately the NLTK ngram models haven't been working for the last few years with Python3. Instead, Jens has implemented a pared-down version of the `NgramModel` class which allows you to generate a word based on some previous context, with the method `generate_one()`. Using this class, train an ngram model based on one of the texts from Problem 1.\n",
    "<br><br>\n",
    "Use your system to produce a number of text samples, 100 words in length\n",
    "per each. Vary the length of the context, $n$, from 2 to 4. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ngram import NgramModel\n",
    "\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Submit a few interesting texts that your system\n",
    "generates,  and  discuss briefly how  the  quality  (and  creativity)  of  the  generated\n",
    "outputs changes with $n$. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your examples and discussion go here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Pointwise Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "In statistical NLP we frequently make independence assumptions about relevant events which are not actually correct in reality. We are asking you to test the independence assumptions of unigram language models.<br><br>\n",
    "\n",
    "$\n",
    "\\mathrm{pmi} = \\frac{P(X_t=w_1,X_{t+1}=w_2)}{P(X_t=w_1)P(X_{t+1}=w_2)} \\approx \\frac{f(w_1,w_2)N}{f(w_1)f(w_2)}\n",
    "$\n",
    "<br><br>\n",
    "\n",
    "*Pointwise mutual information*\n",
    "is a measure of statistical dependence of the events $ X_t = w_1$ and $X_{t+1} = w_2 $; $f(w)$ is the absolute frequency of word $w$ and $N$ is the total size of the corpus.\n",
    "<br><br>\n",
    "\n",
    "If the probability  of  the  next  word  in  the  corpus  being $w_2$\n",
    "is  unaffected  by  the probability of the previous word being $w_1$, then pmi$(w_1,w_2) = 1$; otherwise\n",
    "the pmi is higher or lower than one.\n",
    "<br><br>\n",
    "Calculate the pmi for all successive pairs $(w_1,w_2)$ of words in the King James\n",
    "Bible corpus. Words (not word pairs!) that occur in the corpus less than 10\n",
    "times should be ignored. List the 20 word pairs with the highest pmi value\n",
    "and the 20 word pairs with the lowest pmi value.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Briefly discuss the validity of the independence assumption for unigram models.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your discussion goes here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
