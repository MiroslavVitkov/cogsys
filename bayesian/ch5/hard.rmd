#!/usr/bin/env Rscript


#<!---
library(rmarkdown)
argv <- commandArgs(trailingOnly=FALSE)
fname <- sub("--file=", "", argv[grep("--file=", argv)])
render(fname, output_format="pdf_document")
quit(status=0)
#-->


---
title: "Multivariate Linear Models"
author: Miroslav Vitkov
date: "compiled on: `r Sys.time()`"
---


#5H1
Fit two bivariate Gaussian regressions, using map : (1) body weight as a linear function of territory size ( area ), and (2) body weight as a linear function of groupsize.
```{r, results='hide', message=FALSE}
library( rethinking )
```

```{r}
data( foxes )

# Normalise the data in-place.
foxes$area <- ( foxes$area - mean(foxes$area) ) / sd( foxes$area )
foxes$groupsize <- ( foxes$groupsize - mean(foxes$groupsize) ) / sd( foxes$groupsize )

weight.vs.area <- rethinking::map( alist( weight ~ dnorm( mu , sigma )
                                        , mu <- a + b*area
                                        , a ~ dnorm( 4.5, 1 )
                                        , b ~ dnorm( 0, 10 )
                                        , sigma ~ dunif( 0, 50 ) )
                                 , data=foxes )
weight.vs.area

weight.vs.groupsize <- rethinking::map( alist( weight ~ dnorm( mu , sigma )
                                             , mu <- a + b*groupsize
                                             , a ~ dnorm( 4.5, 1 )
                                             , b ~ dnorm( 0, 10 )
                                             , sigma ~ dunif( 0, 50 ) )
                                      , data=foxes )
weight.vs.groupsize
```

Plot the results of these regressions, displaying the MAP regression line and the 95% interval of the mean.
```{r}
# Read individual parameters off the trained models.
get.param <- function( model, param.name )
{
    c <- model@coef[ param.name ]
    as.numeric( c )
}


a <- get.param( weight.vs.area, "a" )
b <- get.param( weight.vs.area, "b" )
# If I pass `area` with a variable, ggplot doesn't complain but plots it as 0!
ggplot() +
    geom_point( data=foxes, mapping=aes(x=area, y=weight) ) +
    geom_abline( intercept=a, slope=b, colour="blue" ) +
    ggtitle('Foxes')


a <- get.param( weight.vs.groupsize, "a" )
b <- get.param( weight.vs.groupsize, "b" )
# If I pass `area` with a variable, ggplot doesn't complain but plots it as 0!
ggplot() +
    geom_point( data=foxes, mapping=aes(x=groupsize, y=weight) ) +
    geom_abline( intercept=a, slope=b, colour="blue" )

# What is an 'interval of the mean'?
```

Is either variable important for predicting fox body weight?
```{r}
cor( foxes$weight, foxes$area )
cor( foxes$weight, foxes$groupsize )
```

# 5H2
Now fit a multiple linear regression with weight as the outcome and both area and groupsize as predictor variables.
```{r}
multivar <- rethinking::map( alist( weight ~ dnorm( mu , sigma )
                                             , mu <- a + b*area + c*groupsize
                                             , a ~ dnorm( 4.5, 1 )
                                             , b ~ dnorm( 0, 10 )
                                             , c ~ dnorm( 0, 10 )
                                             , sigma ~ dunif( 0, 50 ) )
                                      , data=foxes )
multivar
```

Plot the predictions of the model for each predictor, holding the other predictor constant at its mean.
```{r}
a <- get.param( multivar, "a" )
b <- get.param( multivar, "b" )
c <- get.param( multivar, "c" )

# Why is no plot generated if this is executed within `local({})`?
ggplot() +
    geom_point( data=foxes, mapping=aes(x=area, y=weight) ) +
    geom_abline( intercept=a+c*mean(foxes$groupsize), slope=b, colour="blue" ) +
    ggtitle( "Partial effect of 'area'" )

ggplot() +
    geom_point( data=foxes, mapping=aes(x=groupsize, y=weight) ) +
    geom_abline( intercept=a+b*mean(foxes$area), slope=c, colour="blue" ) + 
    ggtitle( "Partial effect of 'groupsize'" )
```

What does this model say about the importance of each variable?
Why do you get different results than you got in the exercise just above?

\par

The model is compensating the slope of one predictor with the slope of the other.
Thus the more extreme values at high levels of the predictor.
